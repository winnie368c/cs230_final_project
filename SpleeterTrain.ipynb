{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install spleeter tensorflow numpy matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-Jhebt-iaVZ",
        "outputId": "d5be345b-de90-45f4-f60f-9159f696a5cf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spleeter in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: ffmpeg-python<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from spleeter) (0.2.0)\n",
            "Requirement already satisfied: httpx<0.20.0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (0.19.0)\n",
            "Requirement already satisfied: norbert<0.3.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from spleeter) (0.2.1)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from spleeter) (1.5.3)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from spleeter) (0.3.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.67.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python<0.3.0,>=0.2.0->spleeter) (1.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (2024.8.30)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (3.4.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.3.1)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from rfc3986[idna2008]<2,>=1.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.5.0)\n",
            "Requirement already satisfied: httpcore<0.14.0,>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (0.13.7)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (4.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from norbert<0.3.0,>=0.2.1->spleeter) (1.13.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.0->spleeter) (2024.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.4.0,>=0.3.2->spleeter) (7.1.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (4.0.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (0.12.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.2.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To do. Need to figure out how exactly we use the .wav files and how the paths of them should be input to the train and validation csv files"
      ],
      "metadata": {
        "id": "mEqwHGCnAUwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required Python packages\n",
        "!pip install numpy pandas ffmpeg-python norbert typer httpx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3THNyx7oXo8",
        "outputId": "0822a676-1866-4bc6-f224-eae7ceb617ae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: norbert in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from norbert) (1.13.1)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer) (7.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx) (2024.8.30)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from httpx) (3.4.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx) (1.3.1)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from rfc3986[idna2008]<2,>=1.3->httpx) (1.5.0)\n",
            "Requirement already satisfied: httpcore<0.14.0,>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from httpx) (0.13.7)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx) (0.12.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx) (1.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "iG_6-M_Li4R1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access datasets\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Unzip the MUSDB18 dataset\n",
        "zip_path = '/content/drive/MyDrive/musdb18.zip'  # Path to your zip file\n",
        "unzip_folder = '/content/musdb_unzipped'               # Where to unzip files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg5e6aWKjdrv",
        "outputId": "7c7edc1f-f688-494f-ec56-0c5cb3f502d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unzip_folder)\n",
        "\n",
        "print(\"Dataset unzipped to:\", unzip_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrbud3EJjn7O",
        "outputId": "1a911ebf-d690-4f0f-c698-7567fdcff719"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset unzipped to: /content/musdb_unzipped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths for training and validation datasets\n",
        "train_path = os.path.join(unzip_folder, \"train\")\n",
        "validation_path = os.path.join(unzip_folder, \"test\")\n",
        "\n",
        "# Limit dataset to a subset (quick training)\n",
        "train_subset = os.listdir(train_path)[:2]  # Select 2 tracks for training\n",
        "validation_subset = os.listdir(validation_path)[:1]  # Select 1 track for validation\n",
        "\n",
        "# Print subset paths\n",
        "print(\"Training subset:\", train_subset)\n",
        "print(\"Validation subset:\", validation_subset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUgNi-chkmu-",
        "outputId": "2ad54d39-60fe-443d-a9c3-94f683497ea7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training subset: ['Night Panther - Fire.stem.mp4', 'Sweet Lights - You Let Me Down.stem.mp4']\n",
            "Validation subset: ['Lyndsey Ollard - Catching Up.stem.mp4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the Spleeter repository to modify for training\n",
        "!git clone https://github.com/deezer/spleeter.git\n",
        "%cd spleeter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyI0gzJVkpso",
        "outputId": "1d380380-036e-4d51-e704-5fd4f9a84366"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'spleeter'...\n",
            "remote: Enumerating objects: 2675, done.\u001b[K\n",
            "remote: Counting objects: 100% (538/538), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 2675 (delta 463), reused 428 (delta 428), pack-reused 2137 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2675/2675), 9.38 MiB | 12.81 MiB/s, done.\n",
            "Resolving deltas: 100% (1722/1722), done.\n",
            "/content/spleeter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "Pvg2UTcfqKzE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls spleeter/model/functions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZXwXsLHlCKW",
        "outputId": "ea05dc5e-df84-44e2-d48e-566c82640363"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blstm.py  __init__.py  unet.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDQ6_tQciYCd",
        "outputId": "2c148a6d-adbd-4840-9ae1-f7e9293c55e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully replaced all activation functions with sine activation in unet.py\n"
          ]
        }
      ],
      "source": [
        "# Path to unet.py file\n",
        "unet_file = 'spleeter/model/functions/unet.py'\n",
        "\n",
        "# Read the original file content\n",
        "with open(unet_file, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Define sine activation function\n",
        "sine_activation_code = \"\"\"\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define sine activation function\n",
        "def sine_activation(x):\n",
        "    return tf.sin(x)\n",
        "\"\"\"\n",
        "\n",
        "# Add sine activation definition at the top if not already present\n",
        "if \"def sine_activation\" not in content:\n",
        "    content = sine_activation_code + content\n",
        "\n",
        "### Replace the get_conv_activation function manually. Otherwise try to get the\n",
        "### below code to work\n",
        "\n",
        "# # Replace the _get_conv_activation_layer function\n",
        "# content = content.replace(\n",
        "#     \"\"\"\n",
        "# def _get_conv_activation_layer(params: Dict) -> Any:\n",
        "#     \\\"\"\"\n",
        "#     Parameters:\n",
        "#         params (Dict):\n",
        "#             Model parameters.\n",
        "\n",
        "#     Returns:\n",
        "#         Any:\n",
        "#             Required Activation function.\n",
        "#     \\\"\"\"\n",
        "#     conv_activation: str = str(params.get(\"conv_activation\"))\n",
        "#     if conv_activation == \"ReLU\":\n",
        "#         return ReLU()\n",
        "#     elif conv_activation == \"ELU\":\n",
        "#         return ELU()\n",
        "#     return LeakyReLU(0.2)\n",
        "#     \"\"\",\n",
        "#     \"\"\"\n",
        "# def _get_conv_activation_layer(params: Dict) -> Any:\n",
        "#     # Always use sine activation\n",
        "#     return sine_activation\n",
        "#     \"\"\"\n",
        "# )\n",
        "\n",
        "# # Replace the _get_deconv_activation_layer function\n",
        "# content = content.replace(\n",
        "#     \"\"\"\n",
        "# def _get_deconv_activation_layer(params: Dict) -> Any:\n",
        "#     \\\"\"\"\n",
        "#     Parameters:\n",
        "#         params (Dict):\n",
        "#             Model parameters.\n",
        "\n",
        "#     Returns:\n",
        "#         Any:\n",
        "#             Required Activation function.\n",
        "#     \\\"\"\"\n",
        "#     deconv_activation: str = str(params.get(\"deconv_activation\"))\n",
        "#     if deconv_activation == \"LeakyReLU\":\n",
        "#         return LeakyReLU(0.2)\n",
        "#     elif deconv_activation == \"ELU\":\n",
        "#         return ELU()\n",
        "#     return ReLU()\n",
        "#     \"\"\",\n",
        "#     \"\"\"\n",
        "# def _get_deconv_activation_layer(params: Dict) -> Any:\n",
        "#     # Always use sine activation\n",
        "#     return sine_activation\n",
        "#     \"\"\"\n",
        "# )\n",
        "\n",
        "# # Write the updated content back to the file\n",
        "# with open(unet_file, 'w') as file:\n",
        "#     file.write(content)\n",
        "\n",
        "# print(\"Successfully replaced all activation functions with sine activation in unet.py\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Create directories for subset data\n",
        "train_subset_path = os.path.join(unzip_folder, \"train_subset\")\n",
        "validation_subset_path = os.path.join(unzip_folder, \"validation_subset\")\n",
        "os.makedirs(train_subset_path, exist_ok=True)\n",
        "os.makedirs(validation_subset_path, exist_ok=True)\n",
        "\n",
        "# Copy the subset of files to the new directories\n",
        "for track in os.listdir(train_path)[:5]:  # Limit to 5 training examples\n",
        "    shutil.copy(os.path.join(train_path, track), os.path.join(train_subset_path, track))\n",
        "\n",
        "for track in os.listdir(validation_path)[:3]:  # Limit to 3 validation examples\n",
        "    shutil.copy(os.path.join(validation_path, track), os.path.join(validation_subset_path, track))\n",
        "\n",
        "# Update the paths in the configuration\n",
        "quick_config = {\n",
        "    \"train\": {\n",
        "        \"path\": train_subset_path,  # Updated to use subset\n",
        "        \"instrument_list\": [\"vocals\", \"accompaniment\"]\n",
        "    },\n",
        "    \"validation\": {\n",
        "        \"path\": validation_subset_path  # Updated to use subset\n",
        "    },\n",
        "    \"batch_size\": 1,  # Stochastic gradient descent with batch size = 1\n",
        "    \"epoch_count\": 3,  # Only 3 epochs for quick training\n",
        "    \"optimizer\": {\n",
        "        \"type\": \"sgd\",  # Use SGD for optimization\n",
        "        \"learning_rate\": 0.01\n",
        "    },\n",
        "    \"stft\": {\n",
        "        \"frame_length\": 4096,\n",
        "        \"frame_step\": 1024\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"input_shape\": [512, 2],\n",
        "        \"output_shape\": [512, 2]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save the updated configuration as a JSON file\n",
        "config_path = \"configs/quick_config.json\"\n",
        "os.makedirs(os.path.dirname(config_path), exist_ok=True)\n",
        "with open(config_path, \"w\") as config_file:\n",
        "    json.dump(quick_config, config_file)\n",
        "\n",
        "print(f\"Quick training configuration saved to {config_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPYZEs3eqtk6",
        "outputId": "cacc75b9-6257-4721-8b95-210d3cff16f6"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quick training configuration saved to configs/quick_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the training CSV File: We need to build CSV files that align with the input of the model. This depends on the stems that we choose. This can be mix, vocals, and accompaniment, or mix, vocals, drums, bass, other."
      ],
      "metadata": {
        "id": "uvCtQ_zZfv2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the rough draft of the training_subset.csv file"
      ],
      "metadata": {
        "id": "8YZk1GY-fz9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Paths to original CSV files\n",
        "original_train_csv = \"/content/spleeter/configs/musdb_train.csv\"\n",
        "original_validation_csv = \"/content/spleeter/configs/musdb_validation.csv\"\n",
        "\n",
        "# Paths to subset directories\n",
        "train_subset_path = \"/content/musdb_unzipped/train_subset\"\n",
        "validation_subset_path = \"/content/musdb_unzipped/validation_subset\"\n",
        "\n",
        "# Paths to subset CSV files\n",
        "subset_train_csv = \"/content/musdb_unzipped/train_subset/train_subset.csv\"\n",
        "subset_validation_csv = \"/content/musdb_unzipped/validation_subset/validation_subset.csv\"\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs(os.path.dirname(subset_train_csv), exist_ok=True)\n",
        "os.makedirs(os.path.dirname(subset_validation_csv), exist_ok=True)\n",
        "\n",
        "# Load original CSVs\n",
        "train_df = pd.read_csv(original_train_csv)\n",
        "validation_df = pd.read_csv(original_validation_csv)\n",
        "\n",
        "# Add accompaniment_path if missing\n",
        "def add_accompaniment_path(df):\n",
        "    \"\"\"Add accompaniment_path column if missing.\"\"\"\n",
        "    if \"accompaniment_path\" not in df.columns:\n",
        "        df[\"accompaniment_path\"] = df[\"mix_path\"].apply(\n",
        "            lambda x: x.replace(\"mix.wav\", \"accompaniment.wav\")\n",
        "        )\n",
        "    return df\n",
        "\n",
        "train_df = add_accompaniment_path(train_df)\n",
        "validation_df = add_accompaniment_path(validation_df)\n",
        "\n",
        "# Helper function to filter CSV by matching folder names in subset directory\n",
        "def filter_csv_by_subset(original_df, subset_path, dataset_root, subset_name):\n",
        "    \"\"\"Filter rows in the CSV by matching folder names in the subset directory.\"\"\"\n",
        "    # Extract folder names from subset (e.g., \"Alexander Ross - Velvet Curtain.stem.mp4\")\n",
        "    subset_folders = {\n",
        "        os.path.splitext(f)[0].replace(\".stem\", \"\") for f in os.listdir(subset_path) if f.endswith(\".mp4\")\n",
        "    }\n",
        "    print(f\"{subset_name} subset folders: {subset_folders}\")\n",
        "\n",
        "    # Extract folder name and ensure matching\n",
        "    filtered_df = original_df[\n",
        "        original_df[\"mix_path\"].apply(\n",
        "            lambda x: os.path.basename(os.path.dirname(x)) in subset_folders\n",
        "        )\n",
        "    ]\n",
        "    print(f\"{subset_name} subset matches found: {len(filtered_df)}\")\n",
        "\n",
        "    # Adjust paths to replace 'train' with 'train_subset'\n",
        "    for col in [\"mix_path\", \"vocals_path\", \"accompaniment_path\"]:\n",
        "        filtered_df[col] = filtered_df[col].apply(lambda x: x.replace(\"train/\", \"train_subset/\"))\n",
        "\n",
        "    return filtered_df\n",
        "\n",
        "# Filter the train and validation CSVs based on subset directories\n",
        "dataset_root = \"/content/musdb_unzipped\"  # Root directory for unzipped dataset\n",
        "train_subset_df = filter_csv_by_subset(train_df, train_subset_path, dataset_root, \"Training\")\n",
        "# validation_subset_df = filter_csv_by_subset(validation_df, validation_subset_path, dataset_root, \"Validation\")\n",
        "\n",
        "# Save the filtered subset CSVs\n",
        "train_subset_df.to_csv(subset_train_csv, index=False)\n",
        "# validation_subset_df.to_csv(subset_validation_csv, index=False)\n",
        "\n",
        "print(f\"Training subset saved to {subset_train_csv} with {len(train_subset_df)} entries.\")\n",
        "# print(f\"Validation subset saved to {subset_validation_csv} with {len(validation_subset_df)} entries.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdbjgIZDNPLa",
        "outputId": "5f89942b-b924-4b67-9185-ef931670247d"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training subset folders: {'Night Panther - Fire', \"The Wrong'Uns - Rothko\", 'Snowmine - Curfews', 'Alexander Ross - Velvet Curtain', 'Sweet Lights - You Let Me Down'}\n",
            "Training subset matches found: 5\n",
            "Training subset saved to /content/musdb_unzipped/train_subset/train_subset.csv with 5 entries.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-110-c13f50b7efb2>:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df[col] = filtered_df[col].apply(lambda x: x.replace(\"train/\", \"train_subset/\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Edit the csv file so that the accompaniment is 3rd and the others are gone"
      ],
      "metadata": {
        "id": "XiHdDVzHgOUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to the train subset CSV\n",
        "subset_train_csv = \"/content/musdb_unzipped/train_subset/train_subset.csv\"\n",
        "\n",
        "# Load the train subset CSV\n",
        "train_subset_df = pd.read_csv(subset_train_csv)\n",
        "\n",
        "# Keep only the necessary columns in the desired order\n",
        "# Order: mix_path, vocals_path, accompaniment_path, duration\n",
        "columns_to_keep = [\"mix_path\", \"vocals_path\", \"accompaniment_path\", \"duration\"]\n",
        "\n",
        "# Add accompaniment_path if missing\n",
        "if \"accompaniment_path\" not in train_subset_df.columns:\n",
        "    train_subset_df[\"accompaniment_path\"] = train_subset_df[\"mix_path\"].apply(\n",
        "        lambda x: x.replace(\"mixture.wav\", \"accompaniment.wav\")\n",
        "    )\n",
        "\n",
        "# Reorder columns and drop unnecessary ones\n",
        "train_subset_df = train_subset_df[columns_to_keep]\n",
        "\n",
        "# Save the updated train subset CSV\n",
        "train_subset_df.to_csv(subset_train_csv, index=False)\n",
        "\n",
        "print(f\"Updated training subset saved to {subset_train_csv} with {len(train_subset_df)} entries.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4bG5gdjMa-B",
        "outputId": "2344fcdc-1047-42cb-fc7c-bec389579720"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated training subset saved to /content/musdb_unzipped/train_subset/train_subset.csv with 5 entries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the validation csv file"
      ],
      "metadata": {
        "id": "m3_uX-ApgT0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Paths\n",
        "validation_subset_path = \"/content/musdb_unzipped/validation_subset\"\n",
        "subset_validation_csv = \"/content/musdb_unzipped/validation_subset/validation_subset.csv\"\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs(os.path.dirname(subset_validation_csv), exist_ok=True)\n",
        "\n",
        "# Placeholder function to estimate duration (e.g., 240 seconds as default)\n",
        "def estimate_duration(file_path):\n",
        "    \"\"\"Estimate the duration of a file in seconds.\"\"\"\n",
        "    # You can use actual audio libraries (e.g., librosa) to calculate the duration if required\n",
        "    return 240  # Placeholder value\n",
        "\n",
        "# Generate validation subset entries\n",
        "validation_data = []\n",
        "for file in os.listdir(validation_subset_path):\n",
        "    if file.endswith(\".stem.mp4\"):\n",
        "        base_name = os.path.splitext(file)[0].replace(\".stem\", \"\")\n",
        "        mix_path = os.path.join(\"validation_subset\", file)\n",
        "        vocals_path = os.path.join(\"validation_subset\", f\"{base_name}/vocals.wav\")\n",
        "        accompaniment_path = os.path.join(\"validation_subset\", f\"{base_name}/accompaniment.wav\")\n",
        "        duration = estimate_duration(mix_path)\n",
        "        validation_data.append({\n",
        "            \"mix_path\": mix_path,\n",
        "            \"vocals_path\": vocals_path,\n",
        "            \"accompaniment_path\": accompaniment_path,\n",
        "            \"duration\": duration,\n",
        "        })\n",
        "\n",
        "# Save to validation_subset.csv\n",
        "validation_subset_df = pd.DataFrame(validation_data)\n",
        "validation_subset_df.to_csv(subset_validation_csv, index=False)\n",
        "\n",
        "print(f\"Validation subset created and saved to {subset_validation_csv} with {len(validation_subset_df)} entries.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_jVgGedEaES",
        "outputId": "b1d678e0-5d79-4950-987d-9edbccaf4f79"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation subset created and saved to /content/musdb_unzipped/validation_subset/validation_subset.csv with 3 entries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update the validation csv file to include the correct durations"
      ],
      "metadata": {
        "id": "yYqmuMpcgazt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Path to the validation subset CSV\n",
        "subset_validation_csv = \"/content/musdb_unzipped/validation_subset/validation_subset.csv\"\n",
        "\n",
        "# Base directory for unzipped dataset\n",
        "dataset_root = \"/content/musdb_unzipped\"\n",
        "\n",
        "# Function to compute duration using ffmpeg\n",
        "def get_mp4_duration_ffmpeg(file_path):\n",
        "    \"\"\"Get the duration of an mp4 file in seconds using ffmpeg.\"\"\"\n",
        "    try:\n",
        "        probe = ffmpeg.probe(file_path)\n",
        "        duration = float(probe[\"format\"][\"duration\"])\n",
        "        return duration\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Load the validation subset CSV\n",
        "validation_subset_df = pd.read_csv(subset_validation_csv)\n",
        "\n",
        "# Prepend the dataset root path to the mix_path\n",
        "validation_subset_df[\"absolute_mix_path\"] = validation_subset_df[\"mix_path\"].apply(\n",
        "    lambda x: os.path.join(dataset_root, x)\n",
        ")\n",
        "\n",
        "# Calculate and update the duration column\n",
        "validation_subset_df[\"duration\"] = validation_subset_df[\"absolute_mix_path\"].apply(\n",
        "    get_mp4_duration_ffmpeg\n",
        ")\n",
        "\n",
        "# Drop the temporary absolute_mix_path column\n",
        "validation_subset_df.drop(columns=[\"absolute_mix_path\"], inplace=True)\n",
        "\n",
        "# Save the updated validation subset CSV\n",
        "validation_subset_df.to_csv(subset_validation_csv, index=False)\n",
        "\n",
        "print(f\"Updated validation subset with durations saved to {subset_validation_csv}.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAwL2Cs3NYJt",
        "outputId": "4ec22c4b-3c52-40dd-f256-aba75efb8ba9"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated validation subset with durations saved to /content/musdb_unzipped/validation_subset/validation_subset.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "WkrptHIS42nA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separate the audio files into the wav components"
      ],
      "metadata": {
        "id": "T2H47SK1gnfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install musdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhVWOnObQGFQ",
        "outputId": "4ac123fa-5fc3-423c-c839-0bf2da800e9a"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting musdb\n",
            "  Downloading musdb-0.4.2-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from musdb) (1.26.4)\n",
            "Collecting stempeg>=0.2.3 (from musdb)\n",
            "  Downloading stempeg-0.2.3-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pyaml (from musdb)\n",
            "  Downloading pyaml-24.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from musdb) (4.66.6)\n",
            "Requirement already satisfied: ffmpeg-python>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from stempeg>=0.2.3->musdb) (0.2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml->musdb) (6.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python>=0.2.0->stempeg>=0.2.3->musdb) (1.0.0)\n",
            "Downloading musdb-0.4.2-py2.py3-none-any.whl (13 kB)\n",
            "Downloading stempeg-0.2.3-py3-none-any.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-24.9.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyaml, stempeg, musdb\n",
            "Successfully installed musdb-0.4.2 pyaml-24.9.0 stempeg-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Paths to current subsets\n",
        "train_subset_path = \"/content/musdb_unzipped/train_subset\"\n",
        "validation_subset_path = \"/content/musdb_unzipped/validation_subset\"\n",
        "\n",
        "# Paths to new \"whole\" directories\n",
        "train_subset_whole_path = \"/content/musdb_unzipped/train_subset_whole\"\n",
        "validation_subset_whole_path = \"/content/musdb_unzipped/validation_subset_whole\"\n",
        "\n",
        "# Move the original directories\n",
        "shutil.move(train_subset_path, train_subset_whole_path)\n",
        "shutil.move(validation_subset_path, validation_subset_whole_path)\n",
        "\n",
        "print(f\"Moved train_subset to {train_subset_whole_path}\")\n",
        "print(f\"Moved validation_subset to {validation_subset_whole_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUbB_xVfhfWB",
        "outputId": "24bab182-94da-426e-b415-0fc06f7a690f"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved train_subset to /content/musdb_unzipped/train_subset_whole\n",
            "Moved validation_subset to /content/musdb_unzipped/validation_subset_whole\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Paths\n",
        "input_dir = \"/content/musdb_unzipped/train_subset_whole\"  # Input directory containing .stem.mp4 files\n",
        "output_dir = \"/content/musdb_unzipped/train_subset\"       # Output directory for separated .wav files\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Process each .stem.mp4 file\n",
        "for file_name in os.listdir(input_dir):\n",
        "    if file_name.endswith(\".stem.mp4\"):\n",
        "        input_path = os.path.join(input_dir, file_name)\n",
        "        track_name = os.path.splitext(file_name)[0]\n",
        "        track_output_dir = os.path.join(output_dir, track_name)\n",
        "        os.makedirs(track_output_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"Processing {input_path}\")\n",
        "        # Run FFmpeg command for each stem\n",
        "        for i, stem in enumerate([\"mix\", \"drums\", \"bass\", \"other\", \"vocals\"]):\n",
        "            output_path = os.path.join(track_output_dir, f\"{stem}.wav\")\n",
        "            ffmpeg_command = [\n",
        "                \"ffmpeg\", \"-i\", input_path, \"-map\", f\"0:{i}\", output_path, \"-y\"\n",
        "            ]\n",
        "            subprocess.run(ffmpeg_command, check=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "nsb0ysWBneKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "input_dir = \"/content/musdb_unzipped/validation_subset_whole\"  # Input directory containing .stem.mp4 files\n",
        "output_dir = \"/content/musdb_unzipped/validation_subset\"       # Output directory for separated .wav files\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Process each .stem.mp4 file\n",
        "for file_name in os.listdir(input_dir):\n",
        "    if file_name.endswith(\".stem.mp4\"):\n",
        "        input_path = os.path.join(input_dir, file_name)\n",
        "        track_name = os.path.splitext(file_name)[0]\n",
        "        track_output_dir = os.path.join(output_dir, track_name)\n",
        "        os.makedirs(track_output_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"Processing {input_path}\")\n",
        "        # Run FFmpeg command for each stem\n",
        "        for i, stem in enumerate([\"mix\", \"drums\", \"bass\", \"other\", \"vocals\"]):\n",
        "            output_path = os.path.join(track_output_dir, f\"{stem}.wav\")\n",
        "            ffmpeg_command = [\n",
        "                \"ffmpeg\", \"-i\", input_path, \"-map\", f\"0:{i}\", output_path, \"-y\"\n",
        "            ]\n",
        "            subprocess.run(ffmpeg_command, check=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wdwauwan6am",
        "outputId": "4de7ca62-bf1d-4214-d9f0-e982bd162759"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/musdb_unzipped/validation_subset_whole/Lyndsey Ollard - Catching Up.stem.mp4\n",
            "Processing /content/musdb_unzipped/validation_subset_whole/The Long Wait - Dark Horses.stem.mp4\n",
            "Processing /content/musdb_unzipped/validation_subset_whole/Carlos Gonzalez - A Place For Us.stem.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oXmSXXLvgzyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "import json\n",
        "from os.path import join\n",
        "\n",
        "# Define paths for training\n",
        "dataset_root = \"/content/musdb_unzipped\"\n",
        "model_dir = \"/content/spleeter_model\"\n",
        "cache_dir = \"/content/spleeter_cache\"\n",
        "train_csv = join(dataset_root, \"train_subset_whole/train_subset.csv\")\n",
        "validation_csv = join(dataset_root, \"validation_subset_whole/validation_subset.csv\")\n",
        "\n",
        "# Define the complete training configuration\n",
        "TRAIN_CONFIG = {\n",
        "    \"mix_name\": \"mix\",\n",
        "    \"instrument_list\": [\"vocals\", \"accompaniment\"],  # Updated for your use case\n",
        "    \"sample_rate\": 44100,\n",
        "    \"frame_length\": 4096,\n",
        "    \"frame_step\": 1024,\n",
        "    \"T\": 128,\n",
        "    \"F\": 128,\n",
        "    \"model_dir\": model_dir,\n",
        "    \"cache_dir\": cache_dir,\n",
        "    \"train_csv\": train_csv,\n",
        "    \"validation_csv\": validation_csv,\n",
        "    \"train_path\": join(dataset_root, \"train_subset\"),\n",
        "    # \"train_path\": \"train\",\n",
        "    \"n_channels\": 2,\n",
        "    \"chunk_duration\": 4,\n",
        "    \"n_chunks_per_song\": 1,\n",
        "    \"separation_exponent\": 2,\n",
        "    \"mask_extension\": \"zeros\",\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"batch_size\": 2,\n",
        "    \"train_max_steps\": 10,  # Maximum number of training steps\n",
        "    \"throttle_secs\": 20,  # How often summaries are written\n",
        "    \"save_checkpoints_steps\": 100,  # Save checkpoints every 100 steps\n",
        "    \"save_summary_steps\": 5,  # Save summaries every 5 steps\n",
        "    \"random_seed\": 42,  # Fixed random seed for reproducibility\n",
        "    \"model\": {\n",
        "        \"type\": \"unet.unet\",\n",
        "        \"params\": {\n",
        "            \"conv_activation\": \"sine\",\n",
        "            \"deconv_activation\": \"sine\",\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "# Save the training configuration to a file\n",
        "config_path = \"custom_train_config.json\"\n",
        "with open(config_path, \"w\") as config_file:\n",
        "    json.dump(TRAIN_CONFIG, config_file)\n",
        "\n",
        "# Run the training process using subprocess\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "    [\n",
        "        \"spleeter\",\n",
        "        \"train\",\n",
        "        \"-p\", config_path,\n",
        "        \"-d\", dataset_root,\n",
        "        \"--verbose\"\n",
        "    ],\n",
        "    check=True,\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        ")\n",
        "    print(\"Training output:\")\n",
        "    print(result.stdout)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(\"Training failed with the following error:\")\n",
        "    print(e.stderr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ8Cco6YvWaM",
        "outputId": "c386c141-8ac3-4071-932f-aa0bbc53807e"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training output:\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/spleeter_model', '_tf_random_seed': 42, '_save_summary_steps': 5, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.45\n",
            "}\n",
            ", '_keep_checkpoint_max': 2, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:spleeter:Start model training\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/normalization/batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/spleeter_model/model.ckpt-0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/saver.py:1175: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /content/spleeter_model/model.ckpt.\n",
            "INFO:tensorflow:/content/spleeter_model/model.ckpt-0.meta\n",
            "INFO:tensorflow:2100\n",
            "INFO:tensorflow:/content/spleeter_model/model.ckpt-0.data-00000-of-00001\n",
            "INFO:tensorflow:237900\n",
            "INFO:tensorflow:/content/spleeter_model/model.ckpt-0.index\n",
            "INFO:tensorflow:237900\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:spleeter:Loading audio b'/content/musdb_unzipped/train_subset/Sweet Lights - You Let Me Down/mixture.wav' from 193.8951475 to 197.8951475\n",
            "INFO:spleeter:Loading audio b'/content/musdb_unzipped/train_subset/Alexander Ross - Velvet Curtain/mixture.wav' from 255.149388 to 259.149388\n",
            "ERROR:spleeter:An error occurs while loading audio\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 101, in load\n",
            "    probe = ffmpeg.probe(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ffmpeg/_probe.py\", line 23, in probe\n",
            "    raise Error('ffprobe', out, err)\n",
            "ffmpeg._run.Error: ffprobe error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/__autograph_generated_fileeswunbi3.py\", line 45, in safe_load\n",
            "    (data, _) = ag__.converted_call(ag__.ld(self).load, (ag__.converted_call(ag__.ld(path).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(offset).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(duration).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(sample_rate).numpy, (), None, fscope_1)), dict(dtype=ag__.converted_call(ag__.ld(dtype).numpy, (), None, fscope_1)), fscope_1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 103, in load\n",
            "    raise SpleeterError(\n",
            "spleeter.SpleeterError: An error occurs with ffprobe (see ffprobe output below)\n",
            "\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "/content/musdb_unzipped/train_subset/Sweet Lights - You Let Me Down/mixture.wav: No such file or directory\n",
            "\n",
            "ERROR:spleeter:An error occurs while loading audio\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 101, in load\n",
            "    probe = ffmpeg.probe(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ffmpeg/_probe.py\", line 23, in probe\n",
            "    raise Error('ffprobe', out, err)\n",
            "ffmpeg._run.Error: ffprobe error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/__autograph_generated_fileeswunbi3.py\", line 45, in safe_load\n",
            "    (data, _) = ag__.converted_call(ag__.ld(self).load, (ag__.converted_call(ag__.ld(path).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(offset).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(duration).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(sample_rate).numpy, (), None, fscope_1)), dict(dtype=ag__.converted_call(ag__.ld(dtype).numpy, (), None, fscope_1)), fscope_1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 103, in load\n",
            "    raise SpleeterError(\n",
            "spleeter.SpleeterError: An error occurs with ffprobe (see ffprobe output below)\n",
            "\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "/content/musdb_unzipped/train_subset/Alexander Ross - Velvet Curtain/mixture.wav: No such file or directory\n",
            "\n",
            "INFO:spleeter:Loading audio b'/content/musdb_unzipped/train_subset/Snowmine - Curfews/mixture.wav' from 135.5085715 to 139.5085715\n",
            "INFO:spleeter:Loading audio b'/content/musdb_unzipped/train_subset/Night Panther - Fire/mixture.wav' from 104.405442 to 108.405442\n",
            "ERROR:spleeter:An error occurs while loading audio\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 101, in load\n",
            "    probe = ffmpeg.probe(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ffmpeg/_probe.py\", line 23, in probe\n",
            "    raise Error('ffprobe', out, err)\n",
            "ffmpeg._run.Error: ffprobe error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/__autograph_generated_fileeswunbi3.py\", line 45, in safe_load\n",
            "    (data, _) = ag__.converted_call(ag__.ld(self).load, (ag__.converted_call(ag__.ld(path).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(offset).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(duration).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(sample_rate).numpy, (), None, fscope_1)), dict(dtype=ag__.converted_call(ag__.ld(dtype).numpy, (), None, fscope_1)), fscope_1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 103, in load\n",
            "    raise SpleeterError(\n",
            "spleeter.SpleeterError: An error occurs with ffprobe (see ffprobe output below)\n",
            "\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "/content/musdb_unzipped/train_subset/Snowmine - Curfews/mixture.wav: No such file or directory\n",
            "\n",
            "ERROR:spleeter:An error occurs while loading audio\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 101, in load\n",
            "    probe = ffmpeg.probe(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ffmpeg/_probe.py\", line 23, in probe\n",
            "    raise Error('ffprobe', out, err)\n",
            "ffmpeg._run.Error: ffprobe error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/__autograph_generated_fileeswunbi3.py\", line 45, in safe_load\n",
            "    (data, _) = ag__.converted_call(ag__.ld(self).load, (ag__.converted_call(ag__.ld(path).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(offset).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(duration).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(sample_rate).numpy, (), None, fscope_1)), dict(dtype=ag__.converted_call(ag__.ld(dtype).numpy, (), None, fscope_1)), fscope_1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 103, in load\n",
            "    raise SpleeterError(\n",
            "spleeter.SpleeterError: An error occurs with ffprobe (see ffprobe output below)\n",
            "\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "/content/musdb_unzipped/train_subset/Night Panther - Fire/mixture.wav: No such file or directory\n",
            "\n",
            "INFO:spleeter:Loading audio b\"/content/musdb_unzipped/train_subset/The Wrong'Uns - Rothko/mixture.wav\" from 99.0764625 to 103.0764625\n",
            "ERROR:spleeter:An error occurs while loading audio\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 101, in load\n",
            "    probe = ffmpeg.probe(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ffmpeg/_probe.py\", line 23, in probe\n",
            "    raise Error('ffprobe', out, err)\n",
            "ffmpeg._run.Error: ffprobe error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/__autograph_generated_fileeswunbi3.py\", line 45, in safe_load\n",
            "    (data, _) = ag__.converted_call(ag__.ld(self).load, (ag__.converted_call(ag__.ld(path).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(offset).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(duration).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(sample_rate).numpy, (), None, fscope_1)), dict(dtype=ag__.converted_call(ag__.ld(dtype).numpy, (), None, fscope_1)), fscope_1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 103, in load\n",
            "    raise SpleeterError(\n",
            "spleeter.SpleeterError: An error occurs with ffprobe (see ffprobe output below)\n",
            "\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "/content/musdb_unzipped/train_subset/The Wrong'Uns - Rothko/mixture.wav: No such file or directory\n",
            "\n",
            "INFO:spleeter:Loading audio b'/content/musdb_unzipped/train_subset/Alexander Ross - Velvet Curtain/mixture.wav' from 255.149388 to 259.149388\n",
            "INFO:spleeter:Loading audio b'/content/musdb_unzipped/train_subset/Sweet Lights - You Let Me Down/mixture.wav' from 193.8951475 to 197.8951475\n",
            "ERROR:spleeter:An error occurs while loading audio\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 101, in load\n",
            "    probe = ffmpeg.probe(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ffmpeg/_probe.py\", line 23, in probe\n",
            "    raise Error('ffprobe', out, err)\n",
            "ffmpeg._run.Error: ffprobe error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/__autograph_generated_fileeswunbi3.py\", line 45, in safe_load\n",
            "    (data, _) = ag__.converted_call(ag__.ld(self).load, (ag__.converted_call(ag__.ld(path).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(offset).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(duration).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(sample_rate).numpy, (), None, fscope_1)), dict(dtype=ag__.converted_call(ag__.ld(dtype).numpy, (), None, fscope_1)), fscope_1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 103, in load\n",
            "    raise SpleeterError(\n",
            "spleeter.SpleeterError: An error occurs with ffprobe (see ffprobe output below)\n",
            "\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "/content/musdb_unzipped/train_subset/Sweet Lights - You Let Me Down/mixture.wav: No such file or directory\n",
            "\n",
            "ERROR:spleeter:An error occurs while loading audio\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 101, in load\n",
            "    probe = ffmpeg.probe(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ffmpeg/_probe.py\", line 23, in probe\n",
            "    raise Error('ffprobe', out, err)\n",
            "ffmpeg._run.Error: ffprobe error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/__autograph_generated_fileeswunbi3.py\", line 45, in safe_load\n",
            "    (data, _) = ag__.converted_call(ag__.ld(self).load, (ag__.converted_call(ag__.ld(path).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(offset).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(duration).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(sample_rate).numpy, (), None, fscope_1)), dict(dtype=ag__.converted_call(ag__.ld(dtype).numpy, (), None, fscope_1)), fscope_1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 103, in load\n",
            "    raise SpleeterError(\n",
            "spleeter.SpleeterError: An error occurs with ffprobe (see ffprobe output below)\n",
            "\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "/content/musdb_unzipped/train_subset/Alexander Ross - Velvet Curtain/mixture.wav: No such file or directory\n",
            "\n",
            "INFO:spleeter:Loading audio b'/content/musdb_unzipped/train_subset/Snowmine - Curfews/mixture.wav' from 135.5085715 to 139.5085715\n",
            "INFO:spleeter:Loading audio b'/content/musdb_unzipped/train_subset/Night Panther - Fire/mixture.wav' from 104.405442 to 108.405442\n",
            "ERROR:spleeter:An error occurs while loading audio\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 101, in load\n",
            "    probe = ffmpeg.probe(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ffmpeg/_probe.py\", line 23, in probe\n",
            "    raise Error('ffprobe', out, err)\n",
            "ffmpeg._run.Error: ffprobe error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/__autograph_generated_fileeswunbi3.py\", line 45, in safe_load\n",
            "    (data, _) = ag__.converted_call(ag__.ld(self).load, (ag__.converted_call(ag__.ld(path).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(offset).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(duration).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(sample_rate).numpy, (), None, fscope_1)), dict(dtype=ag__.converted_call(ag__.ld(dtype).numpy, (), None, fscope_1)), fscope_1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 103, in load\n",
            "    raise SpleeterError(\n",
            "spleeter.SpleeterError: An error occurs with ffprobe (see ffprobe output below)\n",
            "\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "/content/musdb_unzipped/train_subset/Night Panther - Fire/mixture.wav: No such file or directory\n",
            "\n",
            "INFO:spleeter:Loading audio b\"/content/musdb_unzipped/train_subset/The Wrong'Uns - Rothko/mixture.wav\" from 99.0764625 to 103.0764625\n",
            "ERROR:spleeter:An error occurs while loading audio\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 101, in load\n",
            "    probe = ffmpeg.probe(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ffmpeg/_probe.py\", line 23, in probe\n",
            "    raise Error('ffprobe', out, err)\n",
            "ffmpeg._run.Error: ffprobe error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/__autograph_generated_fileeswunbi3.py\", line 45, in safe_load\n",
            "    (data, _) = ag__.converted_call(ag__.ld(self).load, (ag__.converted_call(ag__.ld(path).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(offset).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(duration).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(sample_rate).numpy, (), None, fscope_1)), dict(dtype=ag__.converted_call(ag__.ld(dtype).numpy, (), None, fscope_1)), fscope_1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 103, in load\n",
            "    raise SpleeterError(\n",
            "spleeter.SpleeterError: An error occurs with ffprobe (see ffprobe output below)\n",
            "\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "/content/musdb_unzipped/train_subset/Snowmine - Curfews/mixture.wav: No such file or directory\n",
            "\n",
            "ERROR:spleeter:An error occurs while loading audio\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 101, in load\n",
            "    probe = ffmpeg.probe(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ffmpeg/_probe.py\", line 23, in probe\n",
            "    raise Error('ffprobe', out, err)\n",
            "ffmpeg._run.Error: ffprobe error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/__autograph_generated_fileeswunbi3.py\", line 45, in safe_load\n",
            "    (data, _) = ag__.converted_call(ag__.ld(self).load, (ag__.converted_call(ag__.ld(path).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(offset).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(duration).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(sample_rate).numpy, (), None, fscope_1)), dict(dtype=ag__.converted_call(ag__.ld(dtype).numpy, (), None, fscope_1)), fscope_1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 103, in load\n",
            "    raise SpleeterError(\n",
            "spleeter.SpleeterError: An error occurs with ffprobe (see ffprobe output below)\n",
            "\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "/content/musdb_unzipped/train_subset/The Wrong'Uns - Rothko/mixture.wav: No such file or directory\n",
            "\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
            "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2024-11-17T05:38:25\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/spleeter_model/model.ckpt-0\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:spleeter:Loading audio b'/content/musdb_unzipped/validation_subset/Lyndsey Ollard - Catching Up.stem.mp4' from 107.6145 to 119.6145\n",
            "INFO:spleeter:Loading audio b'/content/musdb_unzipped/validation_subset/The Long Wait - Dark Horses.stem.mp4' from 146.7605 to 158.7605\n",
            "ERROR:spleeter:An error occurs while loading audio\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 101, in load\n",
            "    probe = ffmpeg.probe(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ffmpeg/_probe.py\", line 23, in probe\n",
            "    raise Error('ffprobe', out, err)\n",
            "ffmpeg._run.Error: ffprobe error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/__autograph_generated_fileeswunbi3.py\", line 45, in safe_load\n",
            "    (data, _) = ag__.converted_call(ag__.ld(self).load, (ag__.converted_call(ag__.ld(path).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(offset).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(duration).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(sample_rate).numpy, (), None, fscope_1)), dict(dtype=ag__.converted_call(ag__.ld(dtype).numpy, (), None, fscope_1)), fscope_1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 103, in load\n",
            "    raise SpleeterError(\n",
            "spleeter.SpleeterError: An error occurs with ffprobe (see ffprobe output below)\n",
            "\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "/content/musdb_unzipped/validation_subset/The Long Wait - Dark Horses.stem.mp4: No such file or directory\n",
            "\n",
            "INFO:spleeter:Loading audio b'/content/musdb_unzipped/validation_subset/Carlos Gonzalez - A Place For Us.stem.mp4' from 119.0095 to 131.0095\n",
            "ERROR:spleeter:An error occurs while loading audio\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 101, in load\n",
            "    probe = ffmpeg.probe(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ffmpeg/_probe.py\", line 23, in probe\n",
            "    raise Error('ffprobe', out, err)\n",
            "ffmpeg._run.Error: ffprobe error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/__autograph_generated_fileeswunbi3.py\", line 45, in safe_load\n",
            "    (data, _) = ag__.converted_call(ag__.ld(self).load, (ag__.converted_call(ag__.ld(path).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(offset).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(duration).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(sample_rate).numpy, (), None, fscope_1)), dict(dtype=ag__.converted_call(ag__.ld(dtype).numpy, (), None, fscope_1)), fscope_1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 103, in load\n",
            "    raise SpleeterError(\n",
            "spleeter.SpleeterError: An error occurs with ffprobe (see ffprobe output below)\n",
            "\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "/content/musdb_unzipped/validation_subset/Lyndsey Ollard - Catching Up.stem.mp4: No such file or directory\n",
            "\n",
            "ERROR:spleeter:An error occurs while loading audio\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 101, in load\n",
            "    probe = ffmpeg.probe(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ffmpeg/_probe.py\", line 23, in probe\n",
            "    raise Error('ffprobe', out, err)\n",
            "ffmpeg._run.Error: ffprobe error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/__autograph_generated_fileeswunbi3.py\", line 45, in safe_load\n",
            "    (data, _) = ag__.converted_call(ag__.ld(self).load, (ag__.converted_call(ag__.ld(path).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(offset).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(duration).numpy, (), None, fscope_1), ag__.converted_call(ag__.ld(sample_rate).numpy, (), None, fscope_1)), dict(dtype=ag__.converted_call(ag__.ld(dtype).numpy, (), None, fscope_1)), fscope_1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spleeter/audio/ffmpeg.py\", line 103, in load\n",
            "    raise SpleeterError(\n",
            "spleeter.SpleeterError: An error occurs with ffprobe (see ffprobe output below)\n",
            "\n",
            "ffprobe version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2007-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "/content/musdb_unzipped/validation_subset/Carlos Gonzalez - A Place For Us.stem.mp4: No such file or directory\n",
            "\n",
            "INFO:tensorflow:Inference Time : 7.90659s\n",
            "INFO:tensorflow:Finished evaluation at 2024-11-17-05:38:33\n",
            "INFO:tensorflow:Saving dict for global step 0: absolute_difference = 0.0, accompaniment_spectrogram = 0.0, global_step = 0, loss = 0.0, vocals_spectrogram = 0.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 0: /content/spleeter_model/model.ckpt-0\n",
            "INFO:tensorflow:Loss for final step: None.\n",
            "INFO:spleeter:Model training done\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P6ysaHOuAl7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Below is for testing different features"
      ],
      "metadata": {
        "id": "qVuokYzXAmdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lh \"/content/musdb_unzipped/validation_subset/Carlos Gonzalez - A Place For Us.stem.mp4\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njxzhe6Gx0p0",
        "outputId": "a105c842-0146-4193-8243-c511b517e3f1"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 39M Nov 17 03:10 '/content/musdb_unzipped/validation_subset/Carlos Gonzalez - A Place For Us.stem.mp4'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzYL3id6yLUt",
        "outputId": "877a7fb7-ea9a-4c63-aced-231990bdf3e8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio_example_mono.mp3\tconda\t images     paper.md\t    README.md\t    tests\n",
            "audio_example.mp3\tconfigs  LICENSE    poetry.lock     spleeter\n",
            "CHANGELOG.md\t\tdocker\t paper.bib  pyproject.toml  spleeter.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mus = musdb.DB(root=\"/content/musdb_unzipped/\")"
      ],
      "metadata": {
        "id": "MB6ppDY2yMjX"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Paths\n",
        "input_dir = \"/content/musdb_unzipped/train_subset_whole\"  # Input directory containing .stem.mp4 files\n",
        "output_dir = \"/content/musdb_unzipped/train_subset\"       # Output directory for separated .wav files\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Process each .stem.mp4 file\n",
        "for file_name in os.listdir(input_dir):\n",
        "    if file_name.endswith(\".stem.mp4\"):\n",
        "        input_path = os.path.join(input_dir, file_name)\n",
        "        track_name = os.path.splitext(file_name)[0]\n",
        "        track_output_dir = os.path.join(output_dir, track_name)\n",
        "        os.makedirs(track_output_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"Processing {input_path}\")\n",
        "        # Run FFmpeg command for each stem\n",
        "        for i, stem in enumerate([\"mix\", \"drums\", \"bass\", \"other\", \"vocals\"]):\n",
        "            output_path = os.path.join(track_output_dir, f\"{stem}.wav\")\n",
        "            ffmpeg_command = [\n",
        "                \"ffmpeg\", \"-i\", input_path, \"-map\", f\"0:{i}\", output_path, \"-y\"\n",
        "            ]\n",
        "            subprocess.run(ffmpeg_command, check=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3w8pSU3kF0h",
        "outputId": "501635b2-f437-47e1-e9a0-713e1fba1062"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/musdb_unzipped/train_subset_whole/Night Panther - Fire.stem.mp4\n",
            "Processing /content/musdb_unzipped/train_subset_whole/Sweet Lights - You Let Me Down.stem.mp4\n",
            "Processing /content/musdb_unzipped/train_subset_whole/The Wrong'Uns - Rothko.stem.mp4\n",
            "Processing /content/musdb_unzipped/train_subset_whole/Snowmine - Curfews.stem.mp4\n",
            "Processing /content/musdb_unzipped/train_subset_whole/Alexander Ross - Velvet Curtain.stem.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NvXb_S4gkeAt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}